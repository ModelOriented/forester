% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compare_models.R
\name{evaluate}
\alias{evaluate}
\title{Function for evaluating and comparing models}
\usage{
evaluate(..., data_test, target, metric = NULL)
}
\arguments{
\item{...}{models to compare. Models should be either \code{forester_model} or \code{explainer} object.}

\item{data_test}{data frame for evaluation models.}

\item{target}{character indicating the target column in data test table.}

\item{metric}{string containing name of metric based on which the model will be selected. 
Metric should be written in lowercase letters. Can be omitted.}
}
\value{
A list containing an object of the class \code{forester_model} and data frame with results.
}
\description{
Function \code{evaluate} enables user to compare one or several models with
the same type of task. Function compares them based on metric which can be chosen by the user 
and returns the best model
}
\examples{
\donttest{
library(DALEX)
data(apartments, package="DALEX")
lightgbm_model <- make_lightgbm(apartments, "m2.price", "regression")
ranger_model <- make_ranger(apartments, "m2.price", "regression")

# Evaluating single model
model_evaluated <- evaluate(ranger_model, 
                             data_test = apartments, 
                             target = "m2.price",
                             metric = "mse")


best_model <- evaluate(lightgbm_model, ranger_model, 
                             data_test = apartments, 
                             target = "m2.price",
                             metric = "rmse")
}
}
\references{
Explanatory Model Analysis. Explore, Explain, and Examine Predictive Models. \url{https://ema.drwhy.ai/}
}
