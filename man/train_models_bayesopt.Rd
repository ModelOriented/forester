% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_models_bayesopt.R
\name{train_models_bayesopt}
\alias{train_models_bayesopt}
\title{Train models with Bayesian Optimization algorithm}
\usage{
train_models_bayesopt(
  train_data,
  y,
  test_data,
  engine,
  type,
  iters.n = 15,
  return_params = FALSE
)
}
\arguments{
\item{train_data}{A training data for models created by `prepare_data`.}

\item{y}{A string which indicates a target column name.}

\item{test_data}{A test data for models created by `prepare_data`.}

\item{engine}{A vector of tree-based models that shall be created. Possible
values are: `ranger`, `xgboost`, `decision_tree`, `lightgbm`, `catboost`.}

\item{type}{A string which determines if machine learning task is the
`classification` or `regression`.}

\item{iters.n}{Number of iterations of BayesOpt function.}

\item{return_params}{If TRUE, returns optimized model params.}
}
\value{
Trained models with optimized parameters. If `retun_params` is `TRUE`, then
returns also training parameters in the one list with models.
}
\description{
Train models with Bayesian Optimization algorithm
}
\examples{
# Binary classification
data(iris)
iris_bin <- iris[1:100, ]
iris_bin$Species[c(1,5,6, 16,18, 22,23,49)] <- rep('versicolor', 8) # noise
iris_bin$Species <- factor(iris_bin$Species)
type <- guess_type(iris_bin, 'Species')
preprocessed_data <- preprocessing(iris_bin, 'Species')
preprocessed_data <- preprocessed_data$data
split_data <-
  train_test_balance(preprocessed_data, 'Species', type = type, balance = FALSE)
train_data <-
  prepare_data(split_data$train,
               'Species',
               c('ranger', 'xgboost', 'decision_tree', 'lightgbm', 'catboost'))
test_data <-
  prepare_data(split_data$test,
               'Species',
               engine = c('ranger', 'xgboost', 'decision_tree', 'lightgbm', 'catboost'),
               predict = TRUE,
               train = split_data$train)

models <- train_models_bayesopt(train_data,
                               'Species',
                               test_data,
                               engine = c('ranger', 'xgboost', 'decision_tree',
                               'lightgbm', 'catboost'),
                               type = type)

# Regression
type <- guess_type(lisbon, 'Price')
preprocessed_data <- preprocessing(lisbon, 'Price')
preprocessed_data <- preprocessed_data$data
split_data2 <-
  train_test_balance(preprocessed_data,
                     y = 'Price',
                     type = type,
                     balance = FALSE)
train_data2 <- prepare_data(split_data2$train,
                     y = 'Price',
                     engine = c('ranger', 'xgboost', 'decision_tree', 'lightgbm', 'catboost')
)
test_data2 <-
  prepare_data(split_data2$test,
               'Price',
               engine = c('ranger', 'xgboost', 'decision_tree', 'lightgbm', 'catboost'),
               predict = TRUE,
               train = split_data2$train)


models2 <-
   train_models_bayesopt(train_data2,
                        'Price',
                         test_data2,
                         engine = c('ranger', 'xgboost', 'decision_tree', 'lightgbm', 'catboost'),
                         type = type,
                         iters.n = 1)
}
