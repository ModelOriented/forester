% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train.R
\name{train}
\alias{train}
\title{Train models with forester}
\usage{
train(
  data,
  y,
  type = "auto",
  engine = c("ranger", "xgboost", "decision_tree", "lightgbm"),
  verbose = TRUE,
  train_test_split = c(0.6, 0.2, 0.2),
  split_seed = NULL,
  bayes_iter = 10,
  random_evals = 10,
  metrics = "auto",
  sort_by = "auto",
  metric_function = NULL,
  metric_function_name = NULL,
  metric_function_decreasing = TRUE,
  best_model_number = 5,
  custom_preprocessing = NULL
)
}
\arguments{
\item{data}{A `data.frame` or `matrix` - data which will be
used to build models. By default model will be trained
on all columns in the `data`.}

\item{y}{A target variable. It can be either
(1) a vector of the same number of observations as `data` or
(2) a character name of variable in the `data` that contains
the target variable.}

\item{type}{A character, one of `binary_clf`/`regression`/`guess` that
sets the type of the task. If `guess` (the default option) then
forester will figure out `type` based on the number of unique values
in the `y` variable.}

\item{engine}{A vector of tree-based models that shall be tested.
Possible values are: `ranger`, `xgboost`, `decision_tree`, `lightgbm`, `catboost`.
All models from this vector will be trained and the best one will be returned.}

\item{verbose}{A logical value, if set to TRUE, provides all information about
training process, if FALSE gives none.}

\item{train_test_split}{A 3-value vector, describing the proportions of train,
test, validation subsets to original data set. Default values are: c(0.6, 0.2, 0.2).}

\item{split_seed}{An integer value describing the seed for the split into
train, test, and validation datasets. By default no seed is set and the split
is performed randomly. Default value is NULL.}

\item{bayes_iter}{An integer value describing number of optimization rounds
used by the Bayesian optimization.}

\item{random_evals}{An integer value describing number of trained models
with different parameters by random search.}

\item{metrics}{A vector of metrics names. By default param set for `auto`, most important metrics are returned.
For `all` all metrics are returned. For `NULL` no metrics returned but still sorted by `sort_by`.}

\item{sort_by}{A string with a name of metric to sort by.
For `auto` models going to be sorted by `mse` for regression and `f1` for classification.}

\item{metric_function}{The self-created function.
It should look like name(predictions, observed) and return the numeric value.
In case of using `metrics` param with a value other than `auto` or `all`, is needed to use a value `metric_function`
in order to see given metric in report. If `sort_by` is equal to `auto` models are sorted by `metric_function`.}

\item{metric_function_name}{The name of the column with values of `metric_function` parameter.
By default `metric_function_name` is `metric_function`.}

\item{metric_function_decreasing}{A logical value indicating how metric_function
should be sorted. `TRUE` by default.}

\item{best_model_number}{Number best models to be chosen as element of the return.
All trained models will be returned as different element of the return.}

\item{custom_preprocessing}{An object returned by the `custom_preprocessing()`
function. By default it is set to NULL, which indicates that basic preprocessing
inside the train will be executed. This process however only makes the necessary actions
for the `train()` to work properly.}
}
\value{
A list of all necessary objects for other functions. It contains:
\itemize{
\item \code{`data`} The original data.
\item \code{`y`} The original target column name.
\item \code{`type`} The type of the ML task. If the user did not specify a type in the
input parameters, the algorithm recognizes, uses and returns the same type.
It could be 'regression' or 'classification'.

\item \code{`deleted_columns`} Column names from the original data frame that have been
removed in the data preprocessing process, e.g. due to too high correlation
with other columns.
\item \code{`preprocessed_data`} The data frame after the preprocessing process - that
means: removing columns with one value for all rows, binarizing the target
column, managing missing values and in advanced preprocessing: deleting
correlated values, deleting columns that are ID-like columns and performing
Boruta algorithm for selecting most important features.
\item \code{`bin_labels`} Labels of binarized target value - {1, 2} values for binary
classification and NULL for regression.
\item \code{`deleted_rows`} The indexes of rows deleted during the preprocessing,
if none were removed the value is NULL.
\item \code{`models_list`} The list of all trained models.
\item \code{`check_report`} Data check report held as a list of strings. It is used
by the `report()` function.
\item \code{`outliers`} The vector of possible outliers detected by the `check_data()`.

\item \code{`best_models_on_valid`} The object containing the best performing models
on the validation dataset.
#' \item \code{`engine`} The list of names of all types of trained models. Possible
values: 'ranger', 'xgboost', 'decision_tree', 'lightgbm', 'catboost'.
\item \code{`raw_train`} The another form of the training dataset (useful for creating
VS plot and predicting on training dataset for catboost and lightgbm models).

\item \code{`train_data`} The training dataset - the part of the source dataset after
preprocessing, balancing and splitting into the training, test and validation
datasets.
\item \code{`test_data`} The test dataset - the part of the source dataset after
preprocessing, balancing and splitting into the training, test and
validation datasets.
\item \code{`valid_data`} The validation dataset - the part of the source dataset after
preprocessing, balancing and splitting into the training, test and validation
datasets.

\item \code{`train_inds`} The vector of integers describing the observation indexes from
the original data frame that went to the training set.
\item \code{`test_inds`} The vector of integers describing the observation indexes from
the original data frame that went to the testing set.
\item \code{`valid_inds`} The vector of integers describing the observation indexes from
the original data frame that went to the validation set.

\item \code{`predictions_train`} Predictions for all trained models on a train dataset.
\item \code{`predictions_test`} Predictions for all trained models on a test dataset.
\item \code{`predictions_valid`} Predictions for all trained models on a validation dataset.

\item \code{`predictions_train_labels`} Predictions for all trained models on a
train dataset with human readable labels.
\item \code{`predictions_test_labels`} Predictions for all trained models on a
test dataset with human readable labels.
\item \code{`predictions_valid_labels`} Predictions for all trained models on a
validation dataset with human readable labels.

\item \code{`predictions_best_train`} Predictions for best trained models on a train dataset.
\item \code{`predictions_best_test`} Predictions for best trained models on a test dataset.
\item \code{`predictions_best_valid`} Predictions for best trained models on a validation dataset.

\item \code{`predictions_best_train_labels`} Predictions for best trained models on a
train dataset with human readable labels.
\item \code{`predictions_best_test_labels`} Predictions for best trained models on a
test dataset with human readable labels.
\item \code{`predictions_best_valid_labels`} Predictions for best trained models on a
validation dataset with human readable labels.

\item \code{`score_train`} The list of metrics for all trained models calculated on a train
dataset. For regression task there are: mse, r2 and mad metrics. For the
classification task there are: f1, auc, recall, precision and accuracy.
\item \code{`score_test`} The list of metrics for all trained models calculated on a test
dataset. For regression task there are: mse, r2 and mad metrics. For the
classification task there are: f1, auc, recall, precision and accuracy.
\item \code{`score_valid`} The list of metrics for all trained models calculated on a validation
dataset. For regression task there are: mse, r2 and mad metrics. For the
classification task there are: f1, auc, recall, precision and accuracy.

\item \code{`test_observed`} Values of y column from the test dataset.
\item \code{`train_observed`} Values of y column from the training dataset.
\item \code{`valid_observed`} Values of y column from the validation dataset.

\item \code{`test_observed_labels`} Values of y column from the test dataset as text labels
(for classification task only).
\item \code{`train_observed_labels`} Values of y column from the training dataset as text
labels (for classification task only).
\item \code{`valid_observed_labels`} Values of y column from the validation dataset as text
labels (for classification task only).
}
}
\description{
The `train()` function is the core function of this package.
The only obligatory arguments are `data` and `target`.
Setting and changing other arguments will affect model
validation strategy, tested model families, and so on.
}
\examples{
\dontrun{
library(forester)
data('lisbon')
train_output <- train(lisbon, 'Price')
train_output$score_valid
}
}
