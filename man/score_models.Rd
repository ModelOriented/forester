% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/score_models.R
\name{score_models}
\alias{score_models}
\title{Score models by suitable metrics}
\usage{
score_models(
  models,
  predictions,
  observed,
  data,
  type,
  time = NULL,
  status = NULL,
  metrics = "auto",
  sort_by = "auto",
  metric_function = NULL,
  metric_function_name = NULL,
  metric_function_decreasing = TRUE,
  engine = NULL,
  tuning = NULL
)
}
\arguments{
\item{models}{A list of models trained by `train_models()` function.}

\item{predictions}{A list of predictions of every engine from the test data.}

\item{observed}{A vector of true values from the test data.}

\item{data}{A data for models created by `prepare_data()` function, used for
Brier score calculations.}

\item{type}{A string, determines if the future task is `binary_clf`, `regression`, or `survival`.}

\item{time}{A string that indicates a time column name for survival analysis task.
Either y, or pair: time, status can be used.}

\item{status}{A string that indicates a status column name for survival analysis task.
Either y, or pair: time, status can be used.}

\item{metrics}{A vector of metrics names. By default param set for `auto`,
most important metrics are returned. For `all` all metrics are returned.
For `NULL` no metrics returned but still sorted by `sort_by`. The metrics
available for the binary classification are: `auc`, `f1`, `recall`, `precision`,
`accuracy`, `sensitivity`, `specificity`, `balanced_accuracy`, and for the
regression: `mse`, `rmse`, `r2`, `mad`, and `mae`.}

\item{sort_by}{String with name of metric to sort by. For `auto` models going
to be sorted by `rmse` for regression and `accuracy` for classification.}

\item{metric_function}{The self-created function.
It should look like name(predictions, observed) and return the numeric value.
In case of using `metrics` param with value other than `auto` or `all`,
is needed to use value `metric_function` in order to see given metric in report.
If `sort_by` is equal to `auto` models are sorted by `metric_function`.}

\item{metric_function_name}{The name of the column with values of param
`metric_function`. By default `metric_function_name` is `metric_function`.}

\item{metric_function_decreasing}{A logical value indicating how metric_function
should be sorted. `TRUE` by default.}

\item{engine}{A vector of strings containing information of engine in `models` list.}

\item{tuning}{A vector of strings containing information of tuning method in `models` list.}
}
\value{
A data.frame with 'no.' - number of model from models,
'engine' - name of the model from models, other metrics columns.
}
\description{
Score models by suitable metrics
}
