% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/calculate_metric.R
\name{calculate_metric}
\alias{calculate_metric}
\title{Metrices for evaluating model's performance.}
\usage{
calculate_metric(metric, predicted, observed, cutoff = 0.5)
}
\arguments{
\item{metric}{character, name of metric. For regression, options are: "mse", "rmse", "mad" and "r2".
For classification, options are: "auc", "recall", "precision", "f1" and "accuracy".}

\item{predicted}{numeric vector containing the prediction target values from model.}

\item{observed}{numeric vector containing actual values of target.}

\item{cutoff}{a cutoff for classification models, needed for measures like recall, precision, ACC, F1. By default 0.5.}
}
\value{
The real value of measured metric between predicted and observed vectors.
}
\description{
Function \code{calculate_metric} returns the value model's performance for classification and regression type measured by a specified metric.
For classification models following metrices can be calculated: F1, accuracy, recall, precision and AUC.
For regression models following metrices can be calculated: mean squared error, R squared, median absolute deviation.
}
\references{
\code{model_performance} from DALEX library. \url{https://github.com/ModelOriented/DALEX/blob/master/R/model_performance.R}
}
