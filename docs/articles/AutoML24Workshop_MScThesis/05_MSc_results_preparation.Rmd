---
title: "Masters Thesis forester: Results preparation"
author: "Hubert Ruczy≈Ñski"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_float: yes
    toc_collapsed: yes
    theme: lumen
    toc_depth: 3
    number_sections: yes
    code_folding: hide
    latex_engine: xelatex
---

```{css, echo=FALSE}
body .main-container {
  max-width: 1820px !important;
  width: 1820px !important;
}
body {
  max-width: 1820px !important;
  width: 1820px !important;
  font-family: Helvetica !important;
  font-size: 16pt !important;
}
h1,h2,h3,h4,h5,h6{
  font-size: 24pt !important;
}
```

# Preprocessing data preparation

In this notebook we will process the data from training and preprocessing in order to enable easier analysis of the results, and reduction of data size.

```{r}
setwd('/net/ascratch/people/plghubertruczynski/forester')
getwd()
```

```{r warning=FALSE}
files <- list.files('MSc_preprocessing_data', pattern = 'RData')
data  <- list()
for (i in 1:length(files)) {
  data[[i]] <- readRDS(paste0('MSc_preprocessing_data/', files[i]))
}
```

```{r eval=FALSE}
dataset           <- c()
removal           <- c()
imputation        <- c()
feature_selection <- c()
duration          <- c()
task_type         <- c()
for (i in 1:25) {
  for (j in 1:38) {
    stringsplt        <- strsplit(data[[i]]$time_df$name[[j]], ':')[[1]]
    dataset           <- c(dataset,    substr(stringsplt[2], 2, nchar(stringsplt[2]) - 7))
    removal           <- c(removal,    substr(stringsplt[3], 1, nchar(stringsplt[3]) - 10))
    imputation        <- c(imputation, substr(stringsplt[4], 1, nchar(stringsplt[4]) - 17))
    feature_selection <- c(feature_selection, stringsplt[5])
    duration          <- c(duration, data[[i]]$time_df$duration[j])
    if (i <= 10) {
      task_type <- c(task_type, 'binary')
    } else if (i > 18) {
      task_type <- c(task_type, 'regression')
    } else {
      task_type <- c(task_type, 'multiclass')
    }
  }
}
duration_df <- data.frame(Dataset = dataset, Removal = removal, Imputation = imputation, 
                          Feature_selection = feature_selection, Task_type = task_type, Duration = duration)
rmarkdown::paged_table(duration_df)
```

```{r eval=FALSE}
dir.create('MSc_processed_results', showWarnings = FALSE)
saveRDS(duration_df, 'MSc_processed_results/preprocessing_duration.RData')
```

# Training data preparation

## Time analysis

```{r}
directories       <- list.dirs('MSc_results')[2:26]
dataset           <- c()
removal           <- c()
imputation        <- c()
feature_selection <- c()
duration          <- c()
task_type         <- c()
for (i in 1:25) {
  names <- readRDS(paste0(directories[i], '/names_times.RData'))
  times <- readRDS(paste0(directories[i], '/list_times.RData'))
  for (j in 1:38) {
    stringsplt        <- strsplit(names[j], ' ')[[1]]
    dataset           <- c(dataset,    stringsplt[2])
    removal           <- c(removal,    stringsplt[4])
    imputation        <- c(imputation, stringsplt[6])
    feature_selection <- c(feature_selection, stringsplt[9])
    duration          <- c(duration, times[j])
    if (i <= 10) {
      task_type <- c(task_type, 'binary')
    } else if (i > 18) {
      task_type <- c(task_type, 'regression')
    } else {
      task_type <- c(task_type, 'multiclass')
    }
  }
}
duration_train_df <- data.frame(Dataset = dataset, Removal = removal, Imputation = imputation, 
                                Feature_selection = feature_selection, Task_type = task_type, Duration = duration)
```

```{r eval=FALSE}
dir.create('MSc_processed_results', showWarnings = FALSE)
saveRDS(duration_train_df, 'MSc_processed_results/training_duration.RData')
```

```{r}
duration_train_df <- readRDS('MSc_processed_results/training_duration.RData')
rmarkdown::paged_table(duration_train_df)
```

## Scores and summaries

As analysis of results for every single model is time consuming, and won't provide too much interesting information, we've decided to summarize those results by calculating maximum, mean, median, and minimum value for each metric. Moreover, we've decided to divide it by engine, however the analysis of all engines is also provided. In fact the latter one was used during the results analysis.

```{r}
res  <- readRDS(paste0(directories[1], '/1.RData'))
res2 <- readRDS(paste0(directories[15], '/1.RData'))
res3 <- readRDS(paste0(directories[18], '/1.RData'))
```

```{r}
summarize_results <- function(data, type) {
  summary_df <- data.frame()
  engines <- c(unique(data$engine), 'all')
  if (type == 'binary') {
    metrics <- c('accuracy', 'auc', 'f1')
  } else if (type == 'regression') {
    metrics <- c('rmse', 'mse', 'r2', 'mae')
  } else {
    metrics <- c('accuracy', 'weighted_precision', 'weighted_recall', 'weighted_f1')
  }
  
  
  for (i in 1:length(engines)) {
    # Choose the engine
    if (engines[i] == 'all') {
      df <- data
    } else {
      df <- data[data$engine == engines[i], ]
    }
    for (j in 1:length(metrics)) {
      metric <- df[[metrics[j]]]
      summ   <- summary(metric)
      record <- data.frame(Engine = engines[i], Metric = metrics[j], Max = summ[[6]],
                           Mean = summ[[4]], Median = summ[[3]], Min = summ[[1]], 
                           Range = (summ[[6]] - summ[[1]]))
      summary_df <- rbind(summary_df, record)
    }
  }
  
  return(summary_df)
}
```

```{r}
rmarkdown::paged_table(summarize_results(res3$score_test, 'regression'))
```

### Summary

Here we actually use the function defined before and calculate the results.

```{r eval=FALSE}
directories      <- list.dirs('MSc_results')[2:26]
training_summary <- list()
task_type <- NULL
dir.create('MSc_processed_results/training_summary', showWarnings = FALSE)

names_binary       <- c('banknote-authentication', 'blood-transfusion-service-center',
                        'breast-w', 'credit-approval', 'credit-g', 'credit-g-mod', 'diabetes',  
                        'kr-vs-kp', 'phoneme', 'phoneme-mod')
names_multiclass   <- c("balance-scale", "car", "car-mod", "dna", "mfeat-karhunen",  "satimage", "satimage-mod", 'wine_quality')
names_regression   <- c('2dplanes', 'bank32nh', 'elevators','elevators-mod','kin8nm', 'kin8nm-mod', 
                       'Mercedes_Benz_Greener_Manufacturing')

names_all <- c(names_binary, names_multiclass, names_regression)

for (i in 1:25) {
  training_summary[[i]] <- list()
  
  if (i <= 10) {
    task_type <- 'binary'
  } else if (i > 18) {
    task_type <- 'regression'
  } else {
    task_type <- 'multiclass'
  }
  
  if (!file.exists(paste0('MSc_processed_results/training_summary/binary_', names_all[i], '.RData')) &&
        !file.exists(paste0('MSc_processed_results/training_summary/regression_', names_all[i], '.RData')) &&
        !file.exists(paste0('MSc_processed_results/training_summary/multiclass_', names_all[i],  '.RData'))) {
    cat('Iteration:', i, '\n', 'The results for', task_type, names_all[i], 'does not exist. Proceeding with calculations. \n')
    task_summary <- list()
    for (j in 1:38) {
      cat('Managing models from iteration:', j, '\n')
      training_summary[[i]][[j]] <- list()
      
      results       <- readRDS(paste0(directories[i], '/', j, '.RData'))
      data          <- results$data
      data_dim      <- dim(results$data)
      score_test    <- results$score_test
      score_train   <- results$score_train
      score_valid   <- results$score_valid
      test_summary  <- summarize_results(results$score_test,  task_type)
      train_summary <- summarize_results(results$score_train, task_type)
      valid_summary <- summarize_results(results$score_valid, task_type)
  
      obs <- list(data = data, data_dim = data_dim, score_test = score_test, 
                  score_train = score_train, score_valid = score_valid, 
                  test_summary = test_summary, train_summary = train_summary, 
                  valid_summary = valid_summary)
      
      suppressWarnings(task_summary[[j]] <- obs)
    }
    names <- readRDS(paste0(directories[i], '/names_times.RData'))
    names(task_summary) <- names
    
    suppressWarnings(training_summary[[i]] <- list(task_summary))
    
    saveRDS(task_summary, paste0(getwd(), '/MSc_processed_results/training_summary/', task_type, '_',  names_all[i], '.RData'))
  } else {
    cat('Iteration:', i, '\n', 'The results for', task_type, names_all[i], 'are already present. Skipping their preparation. \n')
    task_summary <- readRDS(paste0(getwd(), '/MSc_processed_results/training_summary/', task_type, '_', names_all[i],'.RData'))
    
    suppressWarnings(training_summary[[i]] <- task_summary)
  }
}

names(training_summary) <- directories
```


```{r eval=FALSE}
saveRDS(training_summary, 'MSc_processed_results/training_summary.RData')
```

# Extended training summary table

To provide an easier usage of the data, we've decided to create one big table describing all results combined with preprocessing strategy and each stage durations. The resulting file is used in the results analysis.

```{r eval=FALSE}
training_summary       <- readRDS(paste0(getwd(), '/MSc_processed_results/training_summary.RData'))
duration_train_df      <- readRDS(paste0(getwd(), '/MSc_processed_results/training_duration.RData'))
duration_preprocessing <- readRDS(paste0(getwd(), '/MSc_processed_results/preprocessing_duration.RData'))
duration_df            <- duration_train_df
full_duration          <- duration_preprocessing$Duration + duration_df$Duration

duration_df$Preprocessing_duration          <- duration_preprocessing$Duration
duration_df$Preprocessing_duration_fraction <- round(duration_df$Preprocessing_duration / full_duration, 3)
duration_df$Full_duration                   <- full_duration

```

```{r eval=FALSE}
merged_train <- data.frame()
merged_test  <- data.frame()
merged_valid <- data.frame()
merged_dim   <- data.frame()

#extended_summary <- duration_df[rep(1:nrow(duration_df), each = 18), ]
bin_summary      <- duration_df[rep(1:(38*10), each = 18), ]
mcl_summary      <- duration_df[rep((38*10+1):(38*18), each = 24), ]
reg_summary      <- duration_df[rep((38*18+1):nrow(duration_df), each = 24), ]
extended_summary <- rbind(bin_summary, mcl_summary, reg_summary)

for (i in 1:25) {
  for (j in 1:38) {
    merged_train <- rbind(merged_train, training_summary[[i]][[j]]$train_summary)
    merged_test  <- rbind(merged_test,  training_summary[[i]][[j]]$test_summary)
    merged_valid <- rbind(merged_valid, training_summary[[i]][[j]]$valid_summary)
    dim          <- training_summary[[i]][[j]]$data_dim
    dim_df       <- data.frame(Rows = dim[1], Columns = dim[2])
    if (i > 10) {
      each <- 24
    } else {
      each <- 18
    }
    dim_df       <- dim_df[rep(1:nrow(dim_df), each = each), ]
    merged_dim   <- rbind(merged_dim, dim_df)
  }
}
```

```{r eval=FALSE}
extended_training_summary           <- cbind(extended_summary, merged_dim, merged_train)
rownames(extended_training_summary) <- NULL
saveRDS(extended_training_summary, 'MSc_processed_results/training_summary_table.RData')
extended_training_summary <- readRDS('MSc_processed_results/training_summary_table.RData')
rmarkdown::paged_table(extended_training_summary)
```

```{r eval=FALSE}
extended_testing_summary           <- cbind(extended_summary, merged_dim, merged_test)
rownames(extended_testing_summary) <- NULL
saveRDS(extended_testing_summary, 'MSc_processed_results/testing_summary_table.RData')
extended_testing_summary <- readRDS('MSc_processed_results/testing_summary_table.RData')
rmarkdown::paged_table(extended_testing_summary)
```

```{r}
extended_validation_summary           <- cbind(extended_summary, merged_dim, merged_valid)
rownames(extended_validation_summary) <- NULL
saveRDS(extended_validation_summary, 'MSc_processed_results/validation_summary_table.RData')
extended_validation_summary <- readRDS('MSc_processed_results/validation_summary_table.RData')
rmarkdown::paged_table(extended_validation_summary)
```
